{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=cv2.imread('face.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"a\",image)\n",
    "cv2.waitKey()\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"b\",gray)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[744 102  93  93]\n",
      " [325 310 103 103]\n",
      " [828 356 111 111]\n",
      " [892  77  87  87]\n",
      " [571  73 108 108]\n",
      " [129  89  91  91]\n",
      " [389 141  86  86]\n",
      " [228 184  87  87]]\n"
     ]
    }
   ],
   "source": [
    "#haarcascade classifier.xml has a pretrained model in it\n",
    "# TO read the file\n",
    "facecascade=cv2.CascadeClassifier('face.xml') \n",
    "faces=facecascade.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5,minSize=(20,20))\n",
    "print(faces)\n",
    "# coord op is[[x,y,w,h]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),4)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"oc\",image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[744, 102]\n",
      "[325, 310]\n",
      "[828, 356]\n",
      "[892, 77]\n",
      "[571, 73]\n",
      "[129, 89]\n",
      "[389, 141]\n",
      "[228, 184]\n",
      "[[744, 102], [325, 310], [828, 356], [892, 77], [571, 73], [129, 89], [389, 141], [228, 184]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "i=1\n",
    "lf=[]\n",
    "for(x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),4)\n",
    "    s=str(i)\n",
    "    cv2.putText(image,s,(x,y),cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),2)\n",
    "    i=i+1\n",
    "    l=[]\n",
    "    l.append(x)\n",
    "    l.append(y)\n",
    "    lf.append(l)\n",
    "    print(l)\n",
    "#     print(lf)\n",
    "print(lf)\n",
    "cv2.imshow(\"oc\",image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467.78734484806233\n",
      "267.52943763257156\n",
      "150.0966355385756\n",
      "175.41379649275024\n",
      "615.1373830291897\n",
      "357.13582850226607\n",
      "522.474879778923\n",
      "505.0990001969911\n",
      "613.0073409022114\n",
      "341.5918617297549\n",
      "295.39295861614573\n",
      "180.71247881648904\n",
      "159.0125781188394\n",
      "286.24639735724185\n",
      "382.2800020927069\n",
      "748.2579769036879\n",
      "488.82103064414076\n",
      "624.1666444147749\n",
      "321.024921150991\n",
      "763.0943585166909\n",
      "507.05522381689354\n",
      "672.5659818932265\n",
      "442.28949795354623\n",
      "194.28844535895593\n",
      "360.51352263126\n",
      "265.1490147068248\n",
      "137.20787149431334\n",
      "166.6433316997713\n",
      "Person 2 and Person 8,Person 6 and Person 8,Person 7 and Person 8,Person 8 and Person 8,are not following social distancing\n"
     ]
    }
   ],
   "source": [
    "social_dist=\"\"\n",
    "import math\n",
    "for i in range(len(lf)):\n",
    "    for j in range(i+1,len(lf)):\n",
    "        d=math.sqrt(((lf[j][1]-lf[i][1])**2)+((lf[j][0]-lf[i][0])**2))\n",
    "        print(d)\n",
    "    if d<300:\n",
    "        social_dist=social_dist+\"Person \" + str(i+1)+\" and Person \"+str(j+1)+\",\"\n",
    "social_dist+=\"are not following social distancing\"\n",
    "print(social_dist)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"oc\",image)\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
